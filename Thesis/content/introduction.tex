\chapter{Introduction}
  For humans to interact with the world depends on many variables. 
  An important aspect is to recognize, analyze, and estimate the position,
  as well as the shape of objects positioned in the world around. For many years,
  to this day, artificial agents have been developed and deployed in the real world\cite{1087032,10.1007978-981-13-0224-4_40} 
  to imitate how humans interact with it. Similarly, a robot has to understand its environment
  by analyzing and interpreting its surroundings. Understanding exactly this requires first and 
  foremost prior comprehension of the shape of nearby objects. 
  Similar to general robotic applications, the by now more feasible solution for autonomous driving
  needs analogous information of its obstacles to prevent collisions and thus allow for safe guidance
  through traffic. 
  Typically, objects are recorded in a way, which results in unstructured, three-dimensional point
  cloud data, for example, with the help of range scanners or structured light.

  Though obtaining information about samples of an object already provides a way to process a three-dimensional object;
  still, the preferred way to operate is in the form of surface information like tri-or quad-meshes.
  Transforming such point cloud data into meshes is a prevalent problem in the context of computer vision. Thus, numerous
  methods have been developed, aiming to solve that problem\cite{817351,Jakob2015Instant}.
  However, finding use in applications like autonomous driving, reconstructing watertight meshes is a crucial step. Calculating robust collisions,
  analyzing an object's surface or poviding a 3D printable object requires such a complete mesh, without holes, or undefined spots on its surface.
 
  With recent advancements in deep learning and the abundance of readily available data, much work has been poured
  into neural networks which can process the real world robustly. Consequently, solving the same problem of processing 
  unstructured points in three-dimensional space and obtaining polygonal meshes has garnered attention. Though, many methods 
  rely on voxelized data, since neural networks can naturally process structured data better than unstructured spatial data.

  In this work, a novel convolutional neural network configuration is proposed which computes watertight tri-meshes from unstructured point cloud data.
  By deforming an initial base-mesh based on learned tension feature vectors from the data, the network can reliably generate approximations
  even with low-resolution or noisy data. Additionally, a supervised and an unsupervised version of the training process is proposed and evaluated. 
  By providing multi-class training, both versions of the network learn the general reconstruction of objects, even allowing for out of class reconstruction.
  Since this network is the first of its kind, it is essential to assess its capabilities in comparison to the traditional methods. 
  Therefore, part of this work is to identify its strengths and weaknesses and determine where it may find use and how to build upon it.

  The main contributions of this work consist of the following:
  \begin{itemize}
    \item First neural network learning from point cloud data and transforming it directly to a mesh.
    \item Competitive results with multi category learning.
    \item On par or close to computation time of traditional reconstruction methods.
  \end{itemize}

  \subsubsection*{Chapter revision}
  First, a short revision of the basic components, techniques and methods are described in chapter \ref{sec:background} to lay the groundwork for this thesis. In chapter \ref{sec:relatedwork}, 
  numerous traditional, as well as machine learning based methods, are reviewed, which work on the transformation of three-dimensional data to polygonal
  meshes.
  After that, the graph based neural network \emph{points2mesh} is explained in detail, how it handles and learns from point cloud data but also how
  it deforms a base-mesh to approximate the underlying object represented by the data.
  Then, in chapter \ref{chap:results} based on different configurations for the neural network, a \emph{supervised} as well as \emph{unsupervised} version,
  an assortment of resulting meshes are presented and scontrasted against each other.
  Followed by section \ref{chap:evaluation}. a numerical evaluation, and discussion are conducted to assess the capabilities of the network and its 
  varied proposed configurations. By defining a comparable metric for evaluation, related methods achieving similar results can be analyzed and thus 
  measured against each other. To conclude, in chapter \ref{chap:discussion}, some results, advantages and disadvantages of \emph{points2mesh} 
  are weighted up, and finally compared to traditional methods as well as a direct competitor which is utilizing deep learning techniques too.
  The thesis is resolved by taking a look at what has been achieved and possible ways of expanding on the network.