\relax 
\providecommand*\new@tpo@label[2]{}
\AC@reset@newl@bel
\bibstyle{alpha}
\providecommand \oddpage@label [2]{}
\citation{1087032}
\citation{10.1007978-981-13-0224-4_40}
\citation{817351}
\citation{Jakob2015Instant}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:background}{{2}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Machine Learning review}{15}}
\newlabel{back:ptt}{{2.1}{15}}
\newlabel{ml_review}{{2.1}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}stuff}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Weighted reservoir sampling}{15}}
\newlabel{subsec:wrs}{{2.2.1}{15}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:relatedwork}{{3}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Traditional approaches}{17}}
\newlabel{classic_approaches}{{3.1}{17}}
\citation{Lorensen:1987:MCH:37402.37422}
\citation{817351}
\citation{Amenta:2001:PC:376957.376986}
\citation{Lorensen:1987:MCH:37402.37422}
\citation{Groh2017}
\citation{Kazhdan:2006:PSR:1281957.1281965}
\citation{Jakob2015Instant}
\citation{bukenberger2018hierarchical}
\citation{Shilane:2004:TPS}
\citation{7298801}
\citation{shapenet2015}
\citation{xiang2016objectnet3d}
\citation{lpt2013ikea}
\citation{Thingi10K}
\citation{Silberman:ECCV12}
\citation{sunrgb}
\citation{objectnn-shrec17}
\citation{dai2017scannet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Reconstruction methods}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Machine Learning based approaches}{18}}
\newlabel{ml_approaches}{{3.2}{18}}
\citation{Maturana2015VoxNet}
\citation{inproceedings}
\citation{SZB17a}
\citation{articlefusionnet}
\citation{DBLP:journals/corr/QiSNDYG16}
\citation{DBLP:journals/corr/BrockLRW16}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}3D datasets}{19}}
\newlabel{3ddatasets}{{3.2.1}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Learning in 3D}{19}}
\newlabel{learn3d}{{3.2.2}{19}}
\citation{DBLP:journals/corr/QiSMG16}
\citation{qi2017pointnetplusplus}
\citation{DBLP:journals/corr/KlokovL17}
\citation{DBLP:journals/corr/abs-1801-07791}
\citation{PointGrid}
\citation{DBLP:journals/corr/abs-1803-10409}
\citation{DBLP:journals/corr/abs-1712-10215}
\citation{DBLP:journals/corr/QiSMG16}
\citation{qi2017pointnetplusplus}
\citation{DBLP:journals/corr/DaiCSHFN17}
\citation{Groh2017}
\citation{inproceedingsparse}
\citation{DBLP:journals/corr/abs-1710-07563}
\citation{feng2018meshnet}
\citation{Kalogerakis:2010:labelMeshes}
\citation{Sidi:2011:UCS:2024156.2024160}
\citation{Kalogerakis:2017:ShapePFCN}
\citation{cmrKanazawa18}
\citation{DBLP:journals/corr/abs-1711-10669}
\citation{wang2018pixel2mesh}
\citation{mvcTulsiani18}
\citation{DBLP:journals/corr/abs-1804-06032}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Learning 3D reconstruction}{20}}
\newlabel{transform}{{3.2.3}{20}}
\citation{wang2018pixel2mesh}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Graph-based surface reconstruction network}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:methods}{{4}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neural network structure}{21}}
\newlabel{networkconfig}{{4.1}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}General system overview}{21}}
\newlabel{generalsystem}{{4.1.1}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces General workflow of \emph  {points2mesh} network. $\mathcal  {N}_{recon}$ takes a pointcloud $\mathcal  {PC}$ and an initial mesh $\mathcal  {M}_i$ as input, deforms $\mathcal  {M}_i$ based on important features $v_i$ in $\mathcal  {PC}$ to compute an approximate mesh $\mathaccentV {hat}05E{\mathcal  {M}}$\relax }}{22}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:generalconfig}{{4.1}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Traditional way to train neural network. Ground truth data and input are separated. Input may be infered from ground truth data.\relax }}{23}}
\newlabel{fig:training1}{{4.2}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Network training process}{23}}
\newlabel{trainings}{{4.1.2}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Flexconv feature extraction}{23}}
\newlabel{fconv}{{4.1.3}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Alternative approach to train $\mathcal  {N}_{opt}$. Input and ground truth data are the same in this example.\relax }}{24}}
\newlabel{fig:training2}{{4.3}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces $\mathcal  {N}_{flex}$ with point cloud $\mathcal  {PC}$ as input, computing features $v^j$ in three blocks of flexconv layers and a trailing flexpool layer After each convolutional block, weighted random sampling reduces the number of samples of $\mathcal  {PC}$ by a factor of four. Feature vectors $v^j$ are concatenated with their respective positions $x^j$ in a vector $\textbf  {v}$.\relax }}{24}}
\newlabel{fig:flexconv}{{4.4}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces $\mathcal  {N}_{gcn}$ with initial mesh $\mathcal  {M}_i$ as input. Feature vector $\textbf  {v}$ is projected onto the mesh $\mathcal  {M}_i$ and deformed according to it. Then an unpooling layer increases the number of vertices in $\mathcal  {M}_i$. Projecting $\textbf  {v}$ onto the graph and deforming it afterward is repeated two more times.\relax }}{25}}
\newlabel{fig:gcn}{{4.5}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}GCN mesh deformation}{25}}
\newlabel{gcnconv}{{4.1.4}{25}}
\citation{wang2018pixel2mesh}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The \emph  {unpooling} layer of $\mathcal  {N}_{gcn}$ increases the number of vertices by introducing a new node between each neighboring node (\nobreakspace  {}white\nobreakspace  {}) in $\mathcal  {M}_i$. A new node (\nobreakspace  {}green\nobreakspace  {}) is added precisely in the middle of each old edge. Finally, the new nodes are connected, while also updating the neighborhood of the old nodes.\relax }}{26}}
\newlabel{fig:unpool}{{4.6}{26}}
\newlabel{gcnconv}{{4.1.4}{26}}
\newlabel{form:align}{{4.2}{26}}
\citation{wang2018pixel2mesh}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Initial ellipsoid in relation to input pointcloud $\mathcal  {PC}$ before aligning on the left. After \emph  {align graph} layer on the right. Thus, eliminating positional bias and letting the mesh shrink during deformation, rather than letting it grow.\relax }}{27}}
\newlabel{fig:align}{{4.7}{27}}
\newlabel{featureproj}{{4.1.4}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces \emph  {graph projection} layer, assigning feature vectors $\textbf  {v}^j$ to nodes in $\mathcal  {M}_i$ based on the distance to their nearest neighbor in $\mathcal  {PC}$.\relax }}{28}}
\newlabel{fig:proj}{{4.8}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Loss functions}{28}}
\newlabel{lossfuncs}{{4.1.5}{28}}
\newlabel{form:edge}{{4.4}{29}}
\newlabel{form:cos}{{4.5}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Network configurations $\mathcal  {C}$}{29}}
\newlabel{configurations}{{4.1.6}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Baseconfiguration $\mathcal  {C}_1$ of $\mathcal  {N}_{recon}$ showing flex conv feature extraction $\mathcal  {N}_{flex}$ in the upper half, and graph deformation network $\mathcal  {N}_{gcn}$ in the lower part. The complete network $\mathcal  {N}_{recon}$ takes a point cloud and an initial mesh as input, approximating the underlying surface information of the point cloud with $\mathaccentV {hat}05E{\mathcal  {M}_i}$ after deforming the mesh, based on features learned in the point cloud\relax }}{30}}
\newlabel{fig:c1}{{4.9}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Configuration $\mathcal  {C}_2$ of $\mathcal  {N}_{recon}$, showing its difference in $\mathcal  {N}_{gcn}$ to configuration $\mathcal  {C}_1$. $\mathcal  {C}_2$ introduces an extra \emph  {projection}, \emph  {unpooling} layer and a \emph  {graph convolution} block. Thus, allowing for a higher detailed approximate mesh $\mathaccentV {hat}05E{\mathcal  {M}}$ \relax }}{30}}
\newlabel{fig:c2}{{4.10}{30}}
\citation{qi2017pointnetplusplus}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Showing only $\mathcal  {N}_{gcn}$ of $\mathcal  {N}_{recon}$ with $\mathcal  {N}_{flex}$ being the same as in configuration $\mathcal  {C}_{1-3}$. In contrast to $\mathcal  {C}_1$, Configuration $\mathcal  {C}_4$ reduces the number of used layers for deforming the mesh in $\mathcal  {N}_{gcn}$.\relax }}{31}}
\newlabel{fig:c4}{{4.11}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Dataset}{31}}
\newlabel{dataset}{{4.2}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Dataset generation}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Utilized object categories}{32}}
\newlabel{sec:categ}{{4.2.2}{32}}
\citation{817351}
\citation{Jakob2015Instant}
\citation{Liao2018CVPR}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Compared methods}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Result visualization}{33}}
\newlabel{fig:12a}{{5.1a}{34}}
\newlabel{sub@fig:12a}{{(a)}{a}}
\newlabel{fig:12b}{{5.1b}{34}}
\newlabel{sub@fig:12b}{{(b)}{b}}
\newlabel{fig:12c}{{5.1c}{34}}
\newlabel{sub@fig:12c}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Reconstruction from point clouds of airplanes of $\mathcal  {N}_{opt}$. Input point cloud is equal to ground truth point cloud\relax }}{34}}
\newlabel{fig:10}{{5.1}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Reconstruction with 256 samples}}}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Reconstruction with 1024 samples}}}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Reconstruction with 7500 samples}}}{34}}
\newlabel{fig:11a}{{5.2a}{34}}
\newlabel{sub@fig:11a}{{(a)}{a}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Reconstruction from point clouds of guitar of $\mathcal  {N}_{opt}$. Input point cloud is equal to ground truth point cloud with 1024 samples\relax }}{34}}
\newlabel{fig:11}{{5.2}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{34}}
\newlabel{fig:10a}{{5.3a}{34}}
\newlabel{sub@fig:10a}{{(a)}{a}}
\newlabel{fig:10b}{{5.3b}{34}}
\newlabel{sub@fig:10b}{{(b)}{b}}
\newlabel{fig:10c}{{5.3c}{34}}
\newlabel{sub@fig:10c}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Reconstruction from point clouds of chairs of $\mathcal  {N}_{opt}$. Input point cloud is equal to ground truth point cloud with 1024 samples\relax }}{34}}
\newlabel{fig:10}{{5.3}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{34}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{34}}
\citation{Ranellucci2011}
\newlabel{fig:13a}{{5.4a}{35}}
\newlabel{sub@fig:13a}{{(a)}{a}}
\newlabel{fig:13b}{{5.4b}{35}}
\newlabel{sub@fig:13b}{{(b)}{b}}
\newlabel{fig:13c}{{5.4c}{35}}
\newlabel{sub@fig:13c}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces 3D printed reconstruction of guitar, car and toilet of $\mathcal  {N}_{recon}$ and $\mathcal  {C}_1$ with 1024 samples.\relax }}{35}}
\newlabel{fig:13}{{5.4}{35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {3D printed guitar reconstructed with $\mathcal {N}_{recon}$}}}{35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {3D printed car reconstructed with $\mathcal {N}_{recon}$}}}{35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {3D printed toilet reconstructed with $\mathcal {N}_{recon}$}}}{35}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Evaluation}{37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:evaluation}{{6}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Experimental setup}{37}}
\newlabel{subsec:exp}{{6.1}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Evaluation aspects}{38}}
\citation{Stutz2017}
\citation{Stutz2018CVPR}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Evaluation metrics}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Experiment results}{39}}
\newlabel{subsec:results}{{6.2}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Distance metric results}{40}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Distance metric evaluations with 256 samples per point cloud for $\mathcal  {N}_{recon}$. Caluclated with \emph  {meshdistance} metric. Only considering configurations $\mathcal  {C}_1$ and $\mathcal  {C}_2$. Lower values are better.\relax }}{41}}
\newlabel{tab:distance256}{{6.1}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Distance metric evaluations with 1024 samples per point cloud for $\mathcal  {N}_{recon}$. Caluclated with \emph  {meshdistance} metric. Lower values are better.\relax }}{41}}
\newlabel{tab:distance1024}{{6.2}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Distance metric evaluations with 256 samples per point cloud for $\mathcal  {N}_{opt}$. Caluclated with \emph  {meshdistance} metric. Only considering configurations $\mathcal  {C}_1$ and $\mathcal  {C}_2$. Lower values are better.\relax }}{42}}
\newlabel{tab:distance256opt}{{6.3}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Distance metric evaluations with 1024 samples per point cloud for $\mathcal  {N}_{opt}$. Caluclated with \emph  {meshdistance} metric. Lower values are better.\relax }}{42}}
\newlabel{tab:distance1024opt}{{6.4}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {6.5}{\ignorespaces Distance metric evaluations with 7500 samples per point cloud. Caluclated with \emph  {meshdistance} metric.Only considering configurations $\mathcal  {C}_1$ and $\mathcal  {C}_2$. Lower values are better.\relax }}{42}}
\newlabel{tab:distance7500}{{6.5}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Generalization capabilities}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {6.6}{\ignorespaces Distance metric evaluations with 1024 samples per point cloud. Testing with point clouds from outside of trained object categories\relax }}{43}}
\newlabel{tab:generalize}{{6.6}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Varying basemesh $\mathcal  {M}_i$}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {6.7}{\ignorespaces Excerpt of evaluation table. Distance metric evaluations with 1024 samples per point cloud. Initial mesh (\nobreakspace  {}torus mesh\nobreakspace  {}) with a \emph  {genus} of one.\relax }}{44}}
\newlabel{tab:basemesh}{{6.7}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Noise robustness}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {6.8}{\ignorespaces Excerpt of evaluation table. Distance metric evaluations with 1024 samples per point cloud. Comparison of configuration $\mathcal  {C}_1$ trained with and without noise (\emph  {noise level} of 0.01). Inference with noisy data of the same \emph  {noise level}.\relax }}{44}}
\newlabel{tab:noise}{{6.8}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Evaluation time}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {6.9}{\ignorespaces Inference time for configurations $\mathcal  {C}$ and computation time for other techniques\relax }}{45}}
\newlabel{tab:time}{{6.9}{45}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Discussion}{47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:dicussion}{{7}{47}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{49}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:conclusion}{{8}{49}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Outlook}{51}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:outlook}{{9}{51}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{53}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:appendix}{{A}{53}}
\newlabel{optrecon}{{A}{53}}
\newlabel{completeopt}{{A}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Distance metric evaluations with 256 samples per point cloud for $\mathcal  {N}_{opt}$. Caluclated with \emph  {meshdistance} metric. Only considering configurations $\mathcal  {C}_1$ and $\mathcal  {C}_2$. Lower values are better.\relax }}{53}}
\newlabel{tab:distance256opt}{{A.1}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Distance metric evaluations with 1024 samples per point cloud for $\mathcal  {N}_{opt}$. Caluclated with \emph  {meshdistance} metric. Lower values are better.\relax }}{53}}
\newlabel{tab:distance1024opt}{{A.2}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Distance metric evaluations with 7500 samples per point cloud. Caluclated with \emph  {meshdistance} metric.Only considering configurations $\mathcal  {C}_1$ and $\mathcal  {C}_2$. Lower values are better.\relax }}{53}}
\newlabel{tab:distance7500}{{A.3}{53}}
\bibdata{bibliography}
\bibcite{Amenta:2001:PC:376957.376986}{ACK01}
\bibcite{Ranellucci2011}{Ar11}
\bibcite{bukenberger2018hierarchical}{BL18}
\bibcite{DBLP:journals/corr/BrockLRW16}{BLRW16}
\bibcite{817351}{BMR{$^{+}$}99}
\bibcite{1087032}{{Bro}86}
\bibcite{shapenet2015}{CFG{$^{+}$}15}
\bibcite{dai2017scannet}{DCS{$^{+}$}17a}
\bibcite{DBLP:journals/corr/DaiCSHFN17}{DCS{$^{+}$}17b}
\bibcite{DBLP:journals/corr/abs-1803-10409}{DN18}
\bibcite{DBLP:journals/corr/abs-1712-10215}{DRB{$^{+}$}17}
\bibcite{feng2018meshnet}{FFY{$^{+}$}18}
\bibcite{Groh2017}{GRL17}
\bibcite{objectnn-shrec17}{HTT{$^{+}$}17}
\bibcite{articlefusionnet}{HZ16}
\bibcite{Jakob2015Instant}{JTPSH15}
\bibcite{Kalogerakis:2017:ShapePFCN}{KAMC17}
\bibcite{Kazhdan:2006:PSR:1281957.1281965}{KBH06}
\bibcite{Kalogerakis:2010:labelMeshes}{KHS10}
\bibcite{DBLP:journals/corr/KlokovL17}{KL17}
\bibcite{10.1007978-981-13-0224-4_40}{KMS19}
\bibcite{cmrKanazawa18}{KTEM18}
\bibcite{DBLP:journals/corr/abs-1801-07791}{LBSC18}
\bibcite{Lorensen:1987:MCH:37402.37422}{LC87}
\bibcite{PointGrid}{LD18}
\bibcite{Liao2018CVPR}{LDG18}
\bibcite{inproceedingsparse}{LLZ{$^{+}$}17}
\bibcite{lpt2013ikea}{LPT13}
\bibcite{Maturana2015VoxNet}{MS15}
\bibcite{Silberman:ECCV12}{NSF12}
\bibcite{DBLP:journals/corr/abs-1711-10669}{PKS{$^{+}$}17}
\bibcite{DBLP:journals/corr/QiSMG16}{QSMG16}
\bibcite{DBLP:journals/corr/QiSNDYG16}{QSN{$^{+}$}16}
\bibcite{qi2017pointnetplusplus}{QYSG17}
\bibcite{DBLP:journals/corr/abs-1804-06032}{SFH18}
\bibcite{Stutz2018CVPR}{SG18}
\bibcite{Shilane:2004:TPS}{SMKF04}
\bibcite{sunrgb}{SS15}
\bibcite{Stutz2017}{Stu17}
\bibcite{Sidi:2011:UCS:2024156.2024160}{SvKK{$^{+}$}11}
\bibcite{SZB17a}{SZAB17}
\bibcite{DBLP:journals/corr/abs-1710-07563}{TCA{$^{+}$}17}
\bibcite{mvcTulsiani18}{TEM18}
\bibcite{inproceedings}{WSK{$^{+}$}15}
\bibcite{wang2018pixel2mesh}{WZL{$^{+}$}18}
\bibcite{xiang2016objectnet3d}{XKC{$^{+}$}16}
\bibcite{Thingi10K}{ZJ16}
\bibcite{7298801}{ZSK{$^{+}$}15}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{15.32991pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{20.80489pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{29.01736pt}
